# Action Authority v1.3.0: Semantic Safety Bootstrap Guide

## Quick Start

To enable Level 4 Contextual Reasoning in your application, follow these 3 steps:

### Step 1: Import PolicyEngine at Startup

Add to your main application file (e.g., `src/App.tsx` or `src/index.ts`):

```typescript
import { PolicyEngine } from './action-authority/governance/semantic/PolicyEngine';
import { DEFAULT_POLICY_CONFIG } from './action-authority/governance/semantic/defaultConfig';

// Initialize at application startup (before rendering UI)
function initializeSecurityLayers() {
  console.log('[Action Authority v1.3.0] Initializing Level 4: Semantic Safety...');

  try {
    PolicyEngine.initialize(DEFAULT_POLICY_CONFIG);
    console.log('‚úÖ [Level 4] Semantic Safety enabled - Moral Compass activated');
  } catch (error) {
    console.error('‚ùå [Level 4] Failed to initialize:', error);
    throw error; // Fail-closed: Don't start if security layers fail
  }
}

// Call before rendering
initializeSecurityLayers();
```

### Step 2: Pass PolicyResult to HUD

In your useActionAuthority hook consumer:

```typescript
import { useActionAuthority } from './action-authority/hooks/useActionAuthority';
import { ActionAuthorityHUD } from './action-authority/components/ActionAuthorityHUD';

export function MyAudioComponent() {
  const context = {
    contextId: 'my-file-123',
    sourceHash: 'sha256_abc...',
    timestamp: Date.now(),
  };

  // Hook provides policyResult automatically
  const { state, ghost, hudState, holdProgress, policyResult, show, arm, release, confirm, cancel } =
    useActionAuthority(context);

  return (
    <>
      <ActionAuthorityHUD
        hudState={hudState}
        ghost={ghost}
        holdProgress={holdProgress}
        policyResult={policyResult}  // Pass policy result to HUD
        shortHash="0x123abc"
        session="user-session-456"
      />
    </>
  );
}
```

### Step 3: Configure Custom Policies (Optional)

Create `config/semantic-policies.json`:

```json
{
  "version": "1.0.0",
  "customRules": [
    {
      "id": "credit-card-blocking",
      "name": "Block Credit Card Numbers",
      "description": "Prevent transmission of credit card data",
      "type": "CUSTOM_RULE",
      "severity": "CRITICAL",
      "enabled": true,
      "patterns": [
        {
          "regex": "\\b(\\d{4}[\\s-]?){3}\\d{4}\\b",
          "flags": "g"
        }
      ]
    }
  ],
  "coreRulesOverrides": {
    "piiDetection": { "enabled": true },
    "externalApiDetection": { "enabled": true },
    "productionDataProtection": { "enabled": true }
  }
}
```

---

## How It Works

### The Three-Phase Enforcement

**Phase 1: FSM Real-Time Monitoring**
- While user holds (during HOLDING state), PolicyEngine evaluates every 100ms
- If policy violation detected: Instant EXPIRED transition (fail-safe)
- User sees red PolicyViolationOverlay with reason + remediation

**Phase 2: Dispatcher Pre-Execution Gate**
- Before executing action, RED LINE 4.1 checks PolicyEngine again
- If violation found: Execution blocked, result marked FAILED (fail-closed)
- Violation logged to forensic chain (Amendment J)

**Phase 3: Forensic Audit Trail**
- All violations recorded immutably with timestamp, reason, remediation
- Appears in Forensic Viewer as RED violation event
- Supports regulatory compliance and security audits

---

## Understanding the Amendments

### Amendment H: Confidence is Informational

Even if an action has 95% confidence, it won't skip semantic checks:

```typescript
// ‚ùå This DOESN'T happen (confidence doesn't override policy)
if (ghost.confidence > 0.9 && !policyResult.isValid) {
  // Execute anyway
}

// ‚úÖ This DOES happen (policy is always enforced)
if (!policyResult.isValid) {
  // ALWAYS block, regardless of confidence
  transition(AAEvent.EXPIRE);
}
```

### Amendment J: Violation Logging

All blocked violations are logged to the forensic chain:

```typescript
ForensicAuditLog.logEvent({
  type: 'POLICY_VIOLATION_BLOCKED',
  data: {
    auditId: '...',
    forensicEntryId: '...',
    policyResult: {
      reason: 'Attempt to transmit PII detected',
      violations: [
        {
          type: 'PII_EXPOSURE',
          severity: 'CRITICAL',
          reason: 'Email address detected in action parameters',
          remediation: 'Remove email address to proceed',
        }
      ],
      evaluationTimeMs: 0.03,
    },
  },
});
```

### Amendment K: Static Remediation

Remediation messages are **never** generated by the AI:

```typescript
// ‚úÖ Correct: Static string from PolicyEngine
const remediation = violation.suggestedFix;
// "Remove email address from track name to proceed."

// ‚ùå Never do this: AI-generated explanation
const remediation = `The system detected that you're trying to ${generateExplanation()}...`;
```

---

## Policy Violation Response

When a user encounters a policy violation:

1. **HUD Displays Red Card**:
   - Icon: üö´ (prohibition sign)
   - Border: Red (#ef4444)
   - Title: Violation type (e.g., "PII Exposure")
   - Content: Why it was blocked + remediation

2. **FSM Transitions to EXPIRED**:
   - Action is cancelled
   - Ghost overlay disappears
   - User must start over with corrected action

3. **Forensic Entry Created**:
   - Violation logged with full context
   - Timestamp, session ID, violation details
   - Part of immutable audit chain

---

## Common Policy Violations

### PII Exposure

```
Detected: Email address detected in parameters
Remediation: Remove email address before proceeding

‚ùå Blocked action:
export({ trackName: "Song by john@example.com" })

‚úÖ Corrected action:
export({ trackName: "Song by John" })
```

### External API Call

```
Detected: Attempt to contact external service
Remediation: Verify the destination is authorized and trusted

‚ùå Blocked action:
sync({ endpoint: "https://untrusted-service.com/api" })

‚úÖ Corrected action:
sync({ endpoint: "http://localhost:8080/api" })
```

### Production Data Modification

```
Detected: Destructive operation on production data
Remediation: Verify operation is intentional and reversible

‚ùå Blocked action:
execute({ query: "DELETE FROM users", environment: "production" })

‚úÖ Corrected action:
execute({ query: "DELETE FROM test_users", environment: "staging" })
```

---

## Debugging

### Enable Verbose Logging

```typescript
// During development, PolicyEngine logs all evaluations
PolicyEngine.evaluate(context); // Check browser console

// Output:
// [PolicyEngine] Evaluating: "EXPORT_DATA"
// [SemanticAnalyzer] Checking PII patterns...
// [VIOLATION] PII_EXPOSURE: Email address detected
// [REMEDIATION] Remove email address from parameters
```

### Test Policy Blocking

```typescript
// Try to trigger a violation (should be blocked)
const context = buildSemanticContext({
  id: 'test-1',
  type: 'SEND_EMAIL',
  parameters: {
    to: 'user@example.com',  // PII trigger
  },
});

const result = PolicyEngine.evaluate(context);
console.log(result.isValid);  // false
console.log(result.violations[0].reason);  // "Email address detected"
```

### Verify HUD Integration

```typescript
// In your component, check policyResult
console.log('Policy Result:', policyResult);
// Should show: { isValid: false, violations: [...], metadata: {...} }

// In Forensic Viewer, violations should appear as RED events
// Timeline should show: "üî¥ Policy Blocked: PII_EXPOSURE"
```

---

## Performance Tuning

### Cache Behavior

PolicyEngine maintains an LRU cache (100 entries) for fast lookups:

```typescript
// First evaluation: 0.5ms
const result1 = PolicyEngine.evaluate(context);

// Cached lookup: 0.01ms (50x faster)
const result2 = PolicyEngine.evaluate(context);
```

To clear cache (testing only):

```typescript
// Not recommended in production, but available for tests:
// PolicyEngine.clearCache(); // After evaluation with same context
```

### Reducing False Positives

Adjust pattern sensitivity in custom rules:

```json
{
  "id": "strict-email",
  "patterns": [
    {
      "regex": "\\b([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})\\b",
      "flags": "gi"
    }
  ]
}
```

---

## Error Handling

### If PolicyEngine Crashes

PolicyEngine is fail-safe in the FSM and fail-closed in the Dispatcher:

```typescript
// FSM Layer (fail-safe)
try {
  const result = PolicyEngine.evaluate(context);
  if (!result.isValid) {
    expire();
  }
} catch (error) {
  console.warn('Policy check failed, allowing action (fail-safe)');
  // Allow action to proceed - don't lock user out
}

// Dispatcher Layer (fail-closed)
try {
  const result = PolicyEngine.evaluate(context);
  if (!result.isValid) {
    return FAILED;
  }
} catch (error) {
  console.error('Policy check failed, aborting execution (fail-closed)');
  return FAILED; // Never execute if policy check errors
}
```

---

## Regulatory & Compliance

### For GDPR Compliance

PolicyEngine blocks PII transmission:

```typescript
// Blocked: Attempts to collect/transmit personal data
export({ userData: { email, ssn, phone, address } });

// Allowed: Anonymous operation
export({ dataHash: sha256(userData) });
```

### For SOC 2 / ISO 27001

All policy violations are logged for audit:

- ‚úÖ Immutable forensic entries
- ‚úÖ Hash-chained for tamper detection
- ‚úÖ Timestamps and session tracking
- ‚úÖ Exportable for compliance review

### For Financial Services (PCI-DSS)

Blocks credit card data in actions:

```typescript
// Blocked: Credit card in parameters
process({ cardNumber: "4532-1111-2222-3333" });

// Allowed: Tokenized reference
process({ cardToken: "tok_visa_1234" });
```

---

## Support & Questions

For issues or questions about semantic safety:

1. Check `/src/action-authority/governance/semantic/README.md` for full API docs
2. Review test cases in `stress-tests.test.ts` for examples
3. Enable console logging and check browser DevTools
4. Check Forensic Viewer for policy violation timeline

---

**Version**: 1.3.0
**Status**: Level 4 Sealed ‚úÖ
**Moral Compass**: Activated üõ°Ô∏è
**Last Updated**: 2025-12-31
